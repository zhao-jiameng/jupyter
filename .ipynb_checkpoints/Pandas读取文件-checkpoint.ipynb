{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ae350dd",
   "metadata": {},
   "source": [
    "## Pandas读取文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a885bc44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv()         读取文本文件（包括txt）\n",
    "# read_excel()       读取文本文件\n",
    "# read_json()        读取json文件\n",
    "# read_sql_query()   读取sql语句"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558af2ba",
   "metadata": {},
   "source": [
    "### 通用流程\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c2ba7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1、导入库 pandas\n",
    "# 2、找到文件位置\n",
    "# 3、变量名=pd.读写操作方法（文件路径，具体筛选条件，……）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd63ae9",
   "metadata": {},
   "source": [
    "### 一、CSV 文件读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fc99c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df =pd.read_csv()\n",
    "# os动态获取绝对路径 ： os.getcwd()   os.path.json\n",
    "\n",
    "print(df,type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e6072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "一、基本参数\n",
    "1、filepath_or_buffer：数据输入的路径：可以是文件路径、可以是URL，也可以是实现read方法的任意对象。这个参数，就是我们输入的第一个参数。\n",
    "2、sep：读取csv文件时指定的分隔符，默认为逗号。注意：\"csv文件的分隔符\" 和 \"我们读取csv文件时指定的分隔符\" 一定要一致。\n",
    "3.delim_whitespace ：默认为 False，设置为 True 时，表示分割符为空白字符，可以是空格、\"\\t\"等等。不管分隔符是什么，只要是空白字符，那么可以通过delim_whitespace=True进行读取。\n",
    "    所以names和header的使用场景主要如下：\n",
    "        ①. csv文件有表头并且是第一行，那么names和header都无需指定;\n",
    "        ②. csv文件有表头、但表头不是第一行，可能从下面几行开始才是真正的表头和数据，这个时候指定header即可;\n",
    "        ③. csv文件没有表头，全部是纯数据，那么我们可以通过names手动生成表头;\n",
    "        ④. csv文件有表头、但是这个表头你不想用，这个时候同时指定names和header。先用header选出表头和数据，然后再用names将表头替换掉，就等价于将数据读取进来之后再对列名进行rename；\n",
    "4 index_col：我们在读取文件之后所得到的DataFrame的索引默认是0、1、2……，我们可以通过set_index设定索引，但是也可以在读取的时候就指定某列为索引。\n",
    "5.usecols：返回列的子集。如果是类似列表的，则所有元素都必须是位置性的（即文档列中的整数索引），或者是与用户在名称中提供的列名或从文档标题行推断的列名相对应的字符串。如果给出了名称，则不考虑文档标题行\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da94e0b",
   "metadata": {},
   "source": [
    "### 二、通用解析参数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae233a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. encoding:这只编码格式  utf-8  gbk\n",
    "2. dtype：在读取数据的时候，设定字段的类型。比如，公司员工的id一般是：00001234，如果默认读取的时候，会显示为1234，所以这个时候要把他转为字符串类型，才能正常显示为00001234：\n",
    "3. converters：在读取数据的时候对列数据进行变换，例如将id增加10，但是注意 int(x)，在使用converters参数时，解析器默认所有列的类型为 str，所以需要进行类型转换。\n",
    "4. true_values和false_values：指定哪些值应该被清洗为True，哪些值被清洗为False。\n",
    "5、skiprows：表示过滤行，想过滤掉哪些行，就写在一个列表里面传递给skiprows即可。注意的是：这里是先过滤，然后再确定表头\n",
    "6、skipfooter：从文件末尾过滤行\n",
    "7、nrows：设置一次性读入的文件行数，在读入大文件时很有用，比如 16G 内存的PC无法容纳几百 G 的大文件。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5d123f",
   "metadata": {},
   "source": [
    "### 三、空值处理相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434e2564",
   "metadata": {},
   "outputs": [],
   "source": [
    "na_values：该参数可以配置哪些值需要处理成 NaN：\n",
    "pd.read_csv('data\\students.csv', na_values=[\"女\", \"朱梦雪\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b4d76",
   "metadata": {},
   "source": [
    "### 四、时间处理相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce32d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1、parse_dates：指定某些列为时间类型，这个参数一般搭配date_parser使用。\n",
    "    df = pd.read_csv('data\\students.csv',parse_dates=[\"birthday\"])\n",
    "2、date_parser：是用来配合parse_dates参数的，因为有的列虽然是日期，但没办法直接转化，需要我们指定一个解析格式：\n",
    "    df = pd.read_csv('data\\students.csv',parse_dates=[\"birthday\"],date_parser=lambda x:datetime.strptime(x,\"%Y年%m月%d日\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dfd3af8",
   "metadata": {},
   "source": [
    "### 五、分块读入相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85492f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "1、iterator：迭代器, iterator 为 bool类型，默认为False。如果为True，那么返回一个 TextFileReader 对象，以便逐块处理文件。这个在文件很大、内存无法容纳所有数据文件时，可以分批读入，依次处理。\n",
    "    chunk = pd.read_csv('data\\students.csv', iterator=True)\n",
    "    print(chunk.get_chunk(2))\n",
    "    \n",
    "    try:\n",
    "        # 但是在读取完毕之后，再读的话就会报错了\n",
    "        chunk.get_chunk(5)\n",
    "    except StopIteration as e:\n",
    "        print(\"读取完毕\")\n",
    "    # 读取完毕\n",
    "2、chunksize：整型，默认为 None，设置文件块的大小。\n",
    "    chunk = pd.read_csv('data\\students.csv', chunksize=2)\n",
    "    # 还是返回一个类似于迭代器的对象\n",
    "    print(chunk)  \n",
    "    # <pandas.io.parsers.TextFileReader object at 0x0000025501143AF0>\n",
    "\n",
    "    # 调用get_chunk，如果不指定行数，那么就是默认的chunksize\n",
    "    print(chunk.get_chunk())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba894b",
   "metadata": {},
   "source": [
    "### 六、保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac38aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(filename)\n",
    "df.to_excel(filename)\n",
    "df.to_sql(table_name,connection_object)\n",
    "df.to_json(filename)\n",
    "\n",
    "\n",
    "\n",
    "参数：\n",
    "    na_rep:设置空值\n",
    "    sep：设置分隔符"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
